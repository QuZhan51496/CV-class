# 利用 CNN (LeNet-5) 进行手写数字识别

## 1. 引言

本项目基于 LeNet-5 架构实现手写数字识别。使用了包含 0 到 9 数字的灰度图像的 MNIST 数据集进行训练和测试。本项目使用了 PyTorch 框架，完成了三个任务：实现原始 LeNet-5 网络、通过减少卷积核数量进行修改、以及增加 dropout 层以提高泛化能力。

## 2. 数据集

本项目使用了 MNIST 数据集，这是手写数字识别的基准数据集。它包含 60,000 张训练图像和 10,000 张测试图像，大小均为 28x28 像素。每张图像代表一个 0 到 9 之间的数字，因此是一个 10 类分类问题。数据集经过预处理，将像素值归一化到 [0, 1] 的范围。

## 3. 网络结构

本项目选择了 LeNet-5 网络，其整体框架包含卷积层、池化层和全连接层的组合结构，用于手写数字的特征提取和分类。具体实现见代码部分。此后进行了多项改进，包括减少卷积核数量和增加 Dropout 层，以探索性能改进的效果。

- **任务 1：原始 LeNet-5 实现**

  使用 PyTorch 实现了原始 LeNet-5 架构。网络使用 Adam 优化器（学习率为 0.001）和交叉熵损失作为目标函数进行训练。训练过程通过绘制损失曲线进行可视化，并在测试损失最低时保存模型参数。

- **任务 2：减少卷积核数量**

  在任务 2 中，修改了原始 LeNet-5 架构，将每个卷积层中的卷积核数量减少了一半。具体来说，第一个卷积层的输出通道从 6 减少到 3，第二个卷积层的输出通道从 16 减少到 8。此修改旨在探索更简单的模型对识别精度的影响。修改后的架构由于模型容量降低，性能略有下降，但计算效率更高。

- **任务 3：增加 Dropout 层**

  在任务 3 中，向修改后的 LeNet 架构中增加了 dropout 层，以缓解过拟合并提高泛化能力。Dropout 分别以 1%、5%、10% 的概率应用于每个池化层和全连接层之后。增加 dropout 层通过在训练过程中随机丢弃单元，有助于防止过拟合，从而提高了验证集的准确率。

## 4. 结论

通过基于 LeNet-5 架构实现手写数字识别实验，可以得出以下结论：LeNet-5 架构在手写数字识别任务中表现出良好的分类精度，能够较好地捕捉手写数字的特征。

# 利用 VAE 实现 MNIST 重建

## 1. 引言

本项目实现了变分自编码器（VAE）在 MNIST 数据集上的应用，旨在重建手写数字图像。VAE 是一种生成模型，能够学习输入数据的概率分布并生成相似的数据样本。本项目使用了 PyTorch 框架，使用 MNIST 数据集对 VAE 进行训练和评估。

## 2. 数据集

本项目使用了 MNIST 数据集，包含 60,000 张训练图像和 10,000 张测试图像，大小均为 28x28 像素。每张图像代表一个 0 到 9 之间的数字。数据集经过预处理，将像素值归一化到 [0, 1] 的范围，以便于模型训练。

## 3. 网络结构

VAE 包括编码器和解码器两部分，用于对输入图像进行编码压缩到低维潜在空间，再从潜在空间解码还原出输入图像的结构。具体实现细节见代码部分。

## 4. 损失函数

VAE 的损失函数由两部分组成：

- **重建损失**：使用均方误差（MSE）衡量重建图像与原始输入图像之间的差异。

- **KL 散度损失**：衡量潜在分布与标准正态分布之间的差异，以鼓励潜在空间符合高斯分布。

总损失是重建损失和 KL 散度损失的加权和。

## 5. 结论

VAE 成功地从潜在表示中重建了图像，展示了其学习 MNIST 数字的有意义表示的能力。通过对比原始图像和重建图像，可以观察到 VAE 在学习数据分布方面的有效性。

<p align="center">
  <img src="VAE/vis.png" alt="vis" width="500"/>
</p>
